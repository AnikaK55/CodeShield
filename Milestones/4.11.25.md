# Milestone 04/11 Report – Exploring LLM Capabilities

## Updated Proposal

### Problem Statement
Our project investigates the capabilities of **Large Language Models (LLMs)** in detecting security vulnerabilities in Python code. These vulnerabilities include common issues like:

- SQL injection  
- Insecure deserialization  
- Unsafe `eval` use  
- Hardcoded credentials  

As secure software development becomes increasingly critical, we aim to determine whether LLMs can reliably assist in **identifying and explaining** such vulnerabilities.  
> **Note**: Our focus is on detection and explanation only — not on fixing the code.

## Finalized Dataset Plan

We plan to use a **hybrid dataset** consisting of:

- Public datasets from:
  - OWASP Python examples  
  - GitHub Security Advisories  
  - CWE case studies  
- Manually created synthetic examples modeled on the **CWE Top 25 vulnerability types**

Each sample will be labeled with:

- A binary indicator (`vulnerable` or `not vulnerable`)
- The vulnerability type
- A human-written explanation (for benchmarking LLM outputs)

## Objectives

- Evaluate LLM's **detection accuracy** on vulnerable Python code  
- Assess **explanation quality** against human-written references  

## Data Cleaning and Preprocessing

### a) Using Publicly Available Dataset

**Sources**:

- OWASP Python Security Examples  
- GitHub Security Advisories  
- CWE vulnerability case studies  

**Attributes**:

- `code_snippet`  
- `vulnerability_type`  
- `is_vulnerable`  
- `explanation`  

**Prompt Template Example**:
```
You are a Python security expert. Please review the following Python code and determine whether it contains a security vulnerability.
```

**Example Input**:
```python
import os
user_input = input("Enter filename:")
os.system("cat " + user_input)
```

**Preprocessing Steps**:

- Ensured Python syntax validity  
- Removed redundant comments and non-functional code  
- Labeled samples uniformly  
- Balanced secure vs. insecure code examples  

**LLM Response Parsing**:

- Regex and keyword-based classifiers to extract vulnerability presence/type  
- Token overlap and cosine similarity to compare explanations with reference labels  
- Manual review for ambiguous outputs  

### b) Creating Custom Dataset

**Process**:

- Manually generated Python snippets (both vulnerable and safe)  
- Labeled each with vulnerability type + detailed human-written explanation  
- Followed **CWE Top 25** format for realism and consistency  

## Feasibility and Next Steps

### Feasibility

- Scope narrowed to **five vulnerability types**  
- Dataset size is manageable (~80–100 samples total)  
- Prompt format and response parsing are standardized  

### Limitations

- Small dataset size may limit generalization  
- Some vulnerabilities may require **full program context**, which is out of scope  

### Next Steps

- Finalize remaining **20–30 samples and explanations**  
- Conduct initial LLM testing using prompt templates  
- Compare detection and explanation outputs using defined metrics  
- Meet mentor on **4/16** to finalize evaluation plan by **04/25**


